# -*- coding: utf-8 -*-
"""part2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PdDhPMg3tL-A546ITuwA8nijK2grho5R
"""

import pandas as pd
import numpy as np
from prophet import Prophet
import matplotlib.pyplot as plt
from scipy import stats

!pip install -U -q PyDrive
 
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
 
 
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1GCgiWfI9H5vxFIpwDe-GlrQeEvFhX9dh/view?usp=sharing'
 
import pandas as pd
 
# to get the id part of the file
id = link.split("/")[-2]
 
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('1.csv') 
 
link = 'https://drive.google.com/file/d/1pDePt-b00idCZRHnmT_dJW6BaLRS_lzP/view?usp=sharing'
 
import pandas as pd
 
# to get the id part of the file
id = link.split("/")[-2]
 
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('2.csv') 
link = 'https://drive.google.com/file/d/1SUYKh75HdacTugBjgmfpB9-FiI5hqzLv/view?usp=sharing'
 
import pandas as pd
 
# to get the id part of the file
id = link.split("/")[-2]
 
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('3.csv') 
link = 'https://drive.google.com/file/d/1ok5V4osKaasoN7puQLYoMiVoMzYQ0ufK/view?usp=sharing'
 
import pandas as pd
 
# to get the id part of the file
id = link.split("/")[-2]
 
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('4.csv') 
link = 'https://drive.google.com/file/d/1Jl7hak_nznpoaK99Hun6ePomLb_ZGehm/view?usp=sharing'
 
import pandas as pd
 
# to get the id part of the file
id = link.split("/")[-2]
 
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('5.csv') 
link = 'https://drive.google.com/file/d/1yT3WU85UPzbDwpXfcR3m4UYIKGxQAF0u/view?usp=sharing'
 
import pandas as pd
 
# to get the id part of the file
id = link.split("/")[-2]
 
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('6.csv') 
link = 'https://drive.google.com/file/d/15a2YMl5LuLQXVwMTBdZeo-ekk2jzSH-3/view?usp=sharing'
 
import pandas as pd
 
# to get the id part of the file
id = link.split("/")[-2]
 
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('7.csv') 
link = 'https://drive.google.com/file/d/17QsK6_71c8oJjM3QcUgFYu6ew4TD8i2i/view?usp=sharing'
 
import pandas as pd
 
# to get the id part of the file
id = link.split("/")[-2]
 
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('8.csv') 
link = 'https://drive.google.com/file/d/1v6ctHOiQeu9M_WGOu_ByO_OTG375gUC5/view?usp=sharing'
 
import pandas as pd
 
# to get the id part of the file
id = link.split("/")[-2]
 
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('9.csv')

order_items = pd.read_csv("3.csv")
orders = pd.read_csv("6.csv")
order_payments = pd.read_csv("4.csv")
products = pd.read_csv("7.csv")
customers = pd.read_csv("1.csv")
sellers = pd.read_csv("8.csv")
product_category_translation = pd.read_csv("9.csv")

# Merge the datasets
merged = order_items.merge(orders, on='order_id') \
                    .merge(order_payments, on=['order_id']) \
                    .merge(products, on='product_id') \
                    .merge(customers, on='customer_id') \
                    .merge(sellers, on='seller_id') \
                    .merge(product_category_translation, on='product_category_name')

# Save the consolidated dataset to a CSV file
merged.to_csv('/content/brazilian_ecommerce_dataset.csv', index=False)

# Load the dataset
df = pd.read_csv('/content/brazilian_ecommerce_dataset.csv')

# Preprocess the data
# Drop irrelevant columns and handle missing data
df = df.drop(['seller_id', 'freight_value'], axis=1)
df = df.dropna()

# For simplicity taking only 10k rows of data
df = df[:10000]

# Convert categorical variables to numerical values
df = pd.get_dummies(df, columns=['product_category_name', 'customer_state'])

from prophet import Prophet
# Train a time series forecasting model for each product & save those models
forecast_models = {}
unique_product_ids = df['product_id'].unique()

# For demonstration & simplicity taking only 200 products
unique_product_ids = unique_product_ids[0:200]
for product in unique_product_ids:
    product_df = df[df['product_id'] == product].copy()
    # Aggregate sales data by date
    product_df.loc[:, 'order_purchase_date'] = pd.to_datetime(product_df['order_purchase_timestamp']).dt.date
    sales_data = product_df.groupby(['order_purchase_date']).agg({'price': 'sum'}).reset_index()
    sales_data = sales_data.rename(columns={'order_purchase_date': 'ds', 'price': 'y'})
    if len(sales_data) >= 50:
        # Train a time series forecasting model
        m = Prophet()
        m.fit(sales_data)
        forecast_models[product] = m

# Use the forecast models to predict prices for each product

for product in forecast_models:
    m = forecast_models[product]
    future = m.make_future_dataframe(periods=365)
    forecast = m.predict(future)
    future_prices = forecast[['ds', 'yhat']].tail(365)
    mean_price = future_prices['yhat'].mean()
    dynamic_price = mean_price * 1.1 # set dynamic price 10% higher than mean price
    
    print("Product:", product)
    print("Dynamic price:", dynamic_price)

# Aggregate sales data by date
df['order_purchase_date'] = pd.to_datetime(df['order_purchase_timestamp']).dt.date
sales_data = df.groupby(['order_purchase_date']).agg({'price': 'sum'}).reset_index()
sales_data = sales_data.rename(columns={'order_purchase_date': 'ds', 'price': 'y'})

# Remove outliers from sales data using Z-score
sales_data = sales_data[(np.abs(stats.zscore(sales_data['y'])) < 1.5)]

# Train a time series forecasting model
m = Prophet()
m.fit(sales_data)

# Create a future dataframe for forecasting
future = m.make_future_dataframe(periods=365)

# Use the model to make price predictions for each day in the future
forecast = m.predict(future)

# Extract the forecasted prices
forecasted_prices = forecast[['ds', 'yhat']].tail(365)

# Plot the forecasted prices
fig = m.plot(forecast)
plt.scatter(sales_data['ds'], sales_data['y'], color='red', label='Actual')
plt.plot(forecast['ds'], forecast['yhat'], color='blue', label='Forecast')
plt.title('Actual vs Forecasted Daily Sales')
plt.xlabel('Date')
plt.ylabel('Total Sales (BRL)')
plt.legend()
plt.show()



